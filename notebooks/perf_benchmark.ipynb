{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark without tensorrt\n",
    "\n",
    "To benchmark with tensorrt, go to `perf_benchmark_trt.ipynb`.\n",
    "\n",
    "Benchmark only after you have generated the benchmark pickle file (see the `Generate benchmark pickle file` section below)!\n",
    "\n",
    "What is a benchmark pickle file?\n",
    "- It contains a test set generator and a loaded model.\n",
    "- We noticed that the preprocessing steps of VideoPose3D consumed a lot of memory, so Nano started to heavily rely on swap. \n",
    "- We think this may incur I/O bottleneck when inferencing and will produce inaccurate benchmark FPS. \n",
    "- We do this to cut down memory cost and hopefully reduce the I/O bottleneck during benchmark.\n",
    "- We admit that this is a sketchy workaround, and we plan to investigate into the I/O bottleneck issue further later.\n",
    "\n",
    "Remember to keep the GPU warm!\n",
    "- We observed that the FPS tends to be skewed when you are running on CUDA for the first time after a kernel restart.\n",
    "- Hence, remember to \"warm up\" your GPU by running something on CUDA after a kernel restart.\n",
    "- This will give you a more accurate FPS benchmark result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "if osp.basename(os.getcwd()) != 'VideoPose3D': os.chdir('../VideoPose3D')\n",
    "import torch\n",
    "import pickle\n",
    "from common.loss import mpjpe\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../notebooks/benchmark_arc_33333_ch_1024.pkl', 'rb') as f:\n",
    "    test_generator, model_pos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2598, 17, 2])\n",
      "torch.Size([1, 2598, 17, 2])\n",
      "torch.Size([1, 2598, 17, 2])\n",
      "torch.Size([1, 2598, 17, 2])\n",
      "Total eval loss is: 46.201025135815144\n",
      "Total frames: 9424\n",
      "Total elapse time: 2866.8224811553955 ms\n",
      "Avg frame time: 0.30420442287302585 ms\n"
     ]
    }
   ],
   "source": [
    "# per video benchmark\n",
    "# keep warm!\n",
    "test_videos = 3\n",
    "model_pos.eval()\n",
    "if torch.cuda.is_available(): model_pos = model_pos.cuda()\n",
    "epoch_loss_3d_valid = 0\n",
    "num_videos = 0\n",
    "N = 0\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "for cam, batch, batch_2d in test_generator.next_epoch():\n",
    "    inputs_3d = torch.from_numpy(batch.astype('float32'))\n",
    "    inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n",
    "    if torch.cuda.is_available():\n",
    "        inputs_3d = inputs_3d.cuda()\n",
    "        inputs_2d = inputs_2d.cuda()\n",
    "    inputs_traj = inputs_3d[:, :, :1].clone()\n",
    "    inputs_3d[:, :, 0] = 0\n",
    "    predicted_3d_pos = model_pos(inputs_2d)\n",
    "    loss_3d_pos = mpjpe(predicted_3d_pos, inputs_3d)\n",
    "    epoch_loss_3d_valid += inputs_3d.shape[0] * inputs_3d.shape[1] * loss_3d_pos.item()\n",
    "    N += inputs_3d.shape[0] * inputs_3d.shape[1]\n",
    "\n",
    "    num_videos += 1\n",
    "    if num_videos > test_videos: break\n",
    "        \n",
    "toc = time.time()\n",
    "\n",
    "elapse = toc - tic\n",
    "print('Total eval loss is:', 1000 * epoch_loss_3d_valid / N)\n",
    "print('Total frames:', N)\n",
    "print('Total elapse time:', elapse * 1e3, 'ms')\n",
    "print('Avg frame time:', (elapse / N) * 1e3, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total eval loss is: 0.0\n",
      "Total frames: 9424\n",
      "Total elapse time: 410775.92253685 ms\n",
      "Avg frame time: 43.58827700942805 ms\n"
     ]
    }
   ],
   "source": [
    "# per receptive field benchmark\n",
    "# keep warm!\n",
    "test_videos = 3\n",
    "receptive_field = 3*3*3*3*3\n",
    "model_pos.eval()\n",
    "if torch.cuda.is_available(): model_pos = model_pos.cuda()\n",
    "epoch_loss_3d_valid = 0\n",
    "num_videos = 0\n",
    "N = 0\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "for cam, batch, batch_2d in test_generator.next_epoch():\n",
    "    inputs_3d = torch.from_numpy(batch.astype('float32'))\n",
    "    inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n",
    "    num_frames = inputs_2d.shape[1]\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        inputs_3d = inputs_3d.cuda()\n",
    "        inputs_2d = inputs_2d.cuda()\n",
    "    \n",
    "    for i in range(receptive_field, num_frames):\n",
    "        target_inputs_3d = inputs_3d[:,i-receptive_field:i-receptive_field+1,:,:]\n",
    "        chunk_inputs_2d = inputs_2d[:,i-receptive_field:i,:,:]\n",
    "        chunk_inputs_traj = target_inputs_3d[:, :, :1].clone()\n",
    "        target_inputs_3d[:, :, 0] = 0\n",
    "        predicted_3d_pos = model_pos(chunk_inputs_2d)\n",
    "        #loss_3d_pos = mpjpe(predicted_3d_pos, target_inputs_3d)\n",
    "        loss_3d_pos = 0\n",
    "        #epoch_loss_3d_valid += target_inputs_3d.shape[0] * target_inputs_3d.shape[1] * loss_3d_pos.item()\n",
    "        epoch_loss_3d_valid = 0\n",
    "    \n",
    "    N += inputs_3d.shape[0] * inputs_3d.shape[1]\n",
    "    \n",
    "    num_videos += 1\n",
    "    if num_videos > test_videos: break\n",
    "    \n",
    "toc = time.time()\n",
    "\n",
    "elapse = toc - tic\n",
    "print('Total eval loss is:', 1000 * epoch_loss_3d_valid / N)\n",
    "print('Total frames:', N)\n",
    "print('Total elapse time:', elapse * 1e3, 'ms')\n",
    "print('Avg frame time:', (elapse / N) * 1e3, 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate benchmark pickle file\n",
    "\n",
    "I changed the VideoPose3D repo a bit so importing from run will prompt you to paste the command line argument to stdin, and the argparse module will take it from there. The pickle-file-to-dump will contain a test set generator and a loaded model, and it will be saved to PROJECT_ROOT/notebooks.\n",
    "\n",
    "**Remember to do a kernel restart after generating the pickle file!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Line Arguments: -k cpn_ft_h36m_dbb -arc 3,3,3,3,3 -ch 1024 -c checkpoint --evaluate arc_33333_ch_1024_epoch_80.bin --benchmark\n",
      "Namespace(actions='*', architecture='3,3,3,3,3', batch_size=1024, benchmark=True, bone_length_term=True, by_subject=False, causal=False, channels=1024, checkpoint='checkpoint', checkpoint_frequency=10, data_augmentation=True, dataset='h36m', dense=False, disable_optimizations=False, downsample=1, dropout=0.25, epochs=60, evaluate='arc_33333_ch_1024_epoch_80.bin', export_training_curves=False, keypoints='cpn_ft_h36m_dbb', learning_rate=0.001, linear_projection=False, lr_decay=0.95, no_eval=False, no_proj=False, render=False, resume='', stride=1, subjects_test='S9,S11', subjects_train='S1,S5,S6,S7,S8', subjects_unlabeled='', subset=1, test_time_augmentation=True, viz_action=None, viz_bitrate=3000, viz_camera=0, viz_downsample=1, viz_export=None, viz_limit=-1, viz_no_ground_truth=False, viz_output=None, viz_size=5, viz_skip=0, viz_subject=None, viz_video=None, warmup=1)\n",
      "Loading dataset...\n",
      "Preparing data...\n",
      "Loading 2D detections...\n",
      "INFO: Receptive field: 243 frames\n",
      "INFO: Trainable parameter count: 16952371\n",
      "Loading checkpoint checkpoint/arc_33333_ch_1024_epoch_80.bin\n",
      "This model was trained for 80 epochs\n",
      "INFO: Testing on 543344 frames\n",
      "Benchmark flag is on, clearing local variables to release memory...\n",
      "Local variables cleared!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "if osp.basename(os.getcwd()) != 'VideoPose3D': os.chdir('../VideoPose3D')\n",
    "from run import test_generator, model_pos\n",
    "# use the below command line argument for test run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-k cpn_ft_h36m_dbb -arc 3,3,3,3,3 -ch 1024 -c checkpoint --evaluate arc_33333_ch_1024_epoch_80.bin --benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../notebooks/benchmark_arc_33333_ch_1024.pkl', 'wb') as f:\n",
    "    pickle.dump((test_generator, model_pos), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! do a kernel restart after generating the pickle file !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
