{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Line Arguments: -k cpn_ft_h36m_dbb -arc 3,3,3,3,3 -c checkpoint --evaluate pretrained_h36m_cpn.bin --benchmark\n",
      "Namespace(actions='*', architecture='3,3,3,3,3', batch_size=1024, benchmark=True, bone_length_term=True, by_subject=False, causal=False, channels=1024, checkpoint='checkpoint', checkpoint_frequency=10, data_augmentation=True, dataset='h36m', dense=False, disable_optimizations=False, downsample=1, dropout=0.25, epochs=60, evaluate='pretrained_h36m_cpn.bin', export_training_curves=False, keypoints='cpn_ft_h36m_dbb', learning_rate=0.001, linear_projection=False, lr_decay=0.95, no_eval=False, no_proj=False, render=False, resume='', stride=1, subjects_test='S9,S11', subjects_train='S1,S5,S6,S7,S8', subjects_unlabeled='', subset=1, test_time_augmentation=True, viz_action=None, viz_bitrate=3000, viz_camera=0, viz_downsample=1, viz_export=None, viz_limit=-1, viz_no_ground_truth=False, viz_output=None, viz_size=5, viz_skip=0, viz_subject=None, viz_video=None, warmup=1)\n",
      "Loading dataset...\n",
      "Preparing data...\n",
      "Loading 2D detections...\n",
      "INFO: Receptive field: 243 frames\n",
      "INFO: Trainable parameter count: 16952371\n",
      "Loading checkpoint checkpoint/pretrained_h36m_cpn.bin\n",
      "This model was trained for 80 epochs\n",
      "INFO: Testing on 543344 frames\n",
      "Benchmark flag is on, clearing local variables to release memory...\n",
      "Local variables cleared!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "if osp.basename(os.getcwd()) != 'VideoPose3D':\n",
    "    os.chdir('../VideoPose3D')\n",
    "from run import test_generator, model_pos, mpjpe\n",
    "# use the below command line argument for test run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-k cpn_ft_h36m_dbb -arc 3,3,3,3,3 -c checkpoint --evaluate pretrained_h36m_cpn.bin --benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total eval loss is: 48.149985673372186\n"
     ]
    }
   ],
   "source": [
    "model_pos.eval()\n",
    "epoch_loss_3d_valid = 0\n",
    "N = 0\n",
    "\n",
    "for cam, batch, batch_2d in test_generator.next_epoch():\n",
    "    inputs_3d = torch.from_numpy(batch.astype('float32'))\n",
    "    inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n",
    "    if torch.cuda.is_available():\n",
    "        inputs_3d = inputs_3d.cuda()\n",
    "        inputs_2d = inputs_2d.cuda()\n",
    "    inputs_traj = inputs_3d[:, :, :1].clone()\n",
    "    inputs_3d[:, :, 0] = 0\n",
    "    predicted_3d_pos = model_pos(inputs_2d)\n",
    "    loss_3d_pos = mpjpe(predicted_3d_pos, inputs_3d)\n",
    "    epoch_loss_3d_valid += inputs_3d.shape[0] * inputs_3d.shape[1] * loss_3d_pos.item()\n",
    "    N += inputs_3d.shape[0]*inputs_3d.shape[1]\n",
    "    \n",
    "print('Total eval loss is:', 1000 * epoch_loss_3d_valid / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
